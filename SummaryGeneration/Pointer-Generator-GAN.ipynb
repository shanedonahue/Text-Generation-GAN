{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768eee96",
   "metadata": {},
   "source": [
    "# Adversarial Training on Pointer Generator\n",
    "## Introduction\n",
    "    The beginning of the introduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b20d6",
   "metadata": {},
   "source": [
    "## Table Of Contents:\n",
    "* [Load Data & Initialize Model](#load-initialize)\n",
    "* [Train Pointer Generator](#train-global-1)\n",
    "    * [Without Coverage](#train-global-1-sub-1)\n",
    "        * [Generate Tokens](#gen-global-1-sub-1)\n",
    "        * [Rouge Evaluation](#rouge-global-1-sub-1)\n",
    "    * [With Coverage](#train-global-1-sub-2)\n",
    "        * [Generate Tokens](#gen-global-1-sub-2)\n",
    "        * [Rouge Evaluation](#rouge-global-1-sub-2)\n",
    "* [Train Generative Adversarial Network](#train-global-2)\n",
    "    * [Pretrain Discriminator](#train-global-2-sub-1)\n",
    "        * [Generate Tokens](#gen-global-2-sub-1)\n",
    "        * [Rouge Evaluation](#rouge-global-2-sub-1)\n",
    "    * [Adversarial Training](#train-global-2-sub-2)\n",
    "        * [Generate Tokens](#gen-global-2-sub-2)\n",
    "        * [Rouge Evaluation](#rouge-global-2-sub-2)\n",
    "* [Analysis & Conclusion](#analysis-conclusion)\n",
    "* [Limitations & Future Work](#limit-future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b433a88",
   "metadata": {},
   "source": [
    "## Load Data & Initialize Model <a class=\"anchor\" id=\"load-initialize\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb705870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe09c6e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437380 437660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:215: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.enc_fw_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='encoder_forward_cell')\n",
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:216: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.enc_bw_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='encoder_backward_cell')\n",
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:251: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.dec_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, state_is_tuple=False, name='decoder_cell')\n",
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:463: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.dis_enc_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='dis_enc_unit')\n",
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:465: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.dis_dec_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='dis_dec_unit')\n",
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:496: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.bas_enc_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='bas_enc_unit')\n",
      "/Users/shanedonahue/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:498: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.bas_dec_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='bas_dec_unit')\n",
      "2022-12-10 17:53:08.745869: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-12-10 17:53:08.893713: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "from data import Data\n",
    "from model import SummaryModel\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.logging.set_verbosity('ERROR')\n",
    "\n",
    "parser = argparse.ArgumentParser(description = 'Train/Test summarization model', formatter_class = argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# Import Setting\n",
    "parser.add_argument(\"--doc_file\", type = str, default = './data/doc.p', help = 'path to document file')\n",
    "parser.add_argument(\"--vocab_file\", type = str, default = './data/vocab.p', help = 'path to vocabulary file')\n",
    "parser.add_argument(\"--emb_file\", type = str, default = './data/emb.p', help = 'path to embedding file')\n",
    "parser.add_argument(\"--src_time\", type = int, default = 1000, help = 'maximal # of time steps in source text')\n",
    "parser.add_argument(\"--sum_time\", type = int, default = 100, help = 'maximal # of time steps in summary')\n",
    "parser.add_argument(\"--max_oov_bucket\", type = int, default = 280, help = 'maximal # of out-of-vocabulary word in one summary')\n",
    "parser.add_argument(\"--train_ratio\", type = float, default = 0.1, help = 'ratio of training data')\n",
    "parser.add_argument(\"--seed\", type = int, default = 888, help = 'seed for spliting data')\n",
    "\n",
    "# Saving Setting\n",
    "parser.add_argument(\"--log\", type = str, default = './log/', help = 'logging directory')\n",
    "parser.add_argument(\"--save\", type = str, default = './model/', help = 'model saving directory')\n",
    "parser.add_argument(\"--checkpoint\", type = str, help = 'path to checkpoint point')\n",
    "parser.add_argument(\"--autosearch\", type = bool, default = False, help = \"[NOT AVAILABLE] Set 'True' if searching for latest checkpoint\")\n",
    "parser.add_argument(\"--save_interval\", type = int, default = 1760, help = \"Save interval for training\")\n",
    "\n",
    "# Hyperparameter Setting\n",
    "parser.add_argument(\"--batch_size\", type = int, default = 16, help = 'number of samples in one batch')\n",
    "parser.add_argument(\"--gen_lr\", type = float, default = 1e-3, help = 'learning rate for generator')\n",
    "parser.add_argument(\"--dis_lr\", type = float, default = 1e-3, help = 'learning rate for discriminator')\n",
    "parser.add_argument(\"--cov_weight\", type = float, default = 1e-3, help = 'learning rate for coverage')\n",
    "\n",
    "params = vars(parser.parse_args([]))\n",
    "\n",
    "# params['load_pretrain'] = True\n",
    "# # untrained model with glove embedding fine tuned on NYT dataset\n",
    "# params['checkpoint'] = './model/model_untrain_glove-0' # Uncomment when requiring reloading model\n",
    "\n",
    "model = SummaryModel(**params)\n",
    "data = Data(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3b8db2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_next_epoch_test()\n\u001b[1;32m      3\u001b[0m src, ref, gen, tokens, scores, attens, gt_attens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feed_dict \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m      5\u001b[0m     real, fake, real_len, fake_len \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m      6\u001b[0m         [model\u001b[38;5;241m.\u001b[39mreal_reward, model\u001b[38;5;241m.\u001b[39mfake_reward, model\u001b[38;5;241m.\u001b[39msum_len, model\u001b[38;5;241m.\u001b[39mtokens_len], feed_dict\u001b[38;5;241m=\u001b[39mfeed_dict)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(real[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mint\u001b[39m(real_len[\u001b[38;5;241m1\u001b[39m])]))\n",
      "File \u001b[0;32m~/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/data.py:263\u001b[0m, in \u001b[0;36mData.get_next_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m offset \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[0;32m--> 263\u001b[0m     src2idx[j], atten2final[j, :, \u001b[38;5;241m1\u001b[39m], sum2final[j, :, \u001b[38;5;241m2\u001b[39m], src_len[j], sum_len[j], oov[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     atten2final[j, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m j\n\u001b[1;32m    265\u001b[0m     sum2final[j, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m j\n",
      "File \u001b[0;32m~/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/data.py:113\u001b[0m, in \u001b[0;36mData.word2id\u001b[0;34m(self, _context, _summary)\u001b[0m\n\u001b[1;32m    111\u001b[0m         sum2final[i] \u001b[38;5;241m=\u001b[39m oov[summary[i]]\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         \u001b[43msum2final\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[summary[i]]\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src2idx, atten2final, sum2final, src_len, sum_len, json\u001b[38;5;241m.\u001b[39mdumps(oov)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "train_data = data.get_next_epoch()\n",
    "test_data = data.get_next_epoch_test()\n",
    "src, ref, gen, tokens, scores, attens, gt_attens = None, None, None, None, None, None, None\n",
    "for feed_dict in train_data:\n",
    "    real, fake, real_len, fake_len = model.sess.run(\n",
    "        [model.real_reward, model.fake_reward, model.sum_len, model.tokens_len], feed_dict=feed_dict)\n",
    "    print(np.mean(real[1, 0:int(real_len[1])]))\n",
    "    print(np.mean(fake[1, 0:int(fake_len[1])]))\n",
    "    break\n",
    "\n",
    "for feed_dict in test_data:\n",
    "    tokens, scores, attens = model.beam_search(feed_dict)\n",
    "    src, ref, gen = data.id2word(feed_dict, tokens)\n",
    "    gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "#     print(src, ref, gen, gt_attens)\n",
    "    print(gen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42c570",
   "metadata": {},
   "source": [
    "## Train Pointer Generator<a class=\"anchor\" id=\"train-global-1\"></a>\n",
    "### Train without coverage<a class=\"anchor\" id=\"train-global-1-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5727c9ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from step 0\n",
      "Train Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db64a1e75bbd45c59b5907920e81912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m train_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_next_epoch()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoverage_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/model.py:854\u001b[0m, in \u001b[0;36mSummaryModel.train_one_epoch\u001b[0;34m(self, generator, total_n_batch, coverage_on, model_name)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03m    Train for one epoch\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    853\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_global_step)\n\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feed_dict \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(generator, total\u001b[38;5;241m=\u001b[39mtotal_n_batch, display\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    855\u001b[0m     feed_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoverage_on:0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m coverage_on\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupervised_opt, feed_dict\u001b[38;5;241m=\u001b[39mfeed_dict)\n",
      "File \u001b[0;32m~/miniforge3/envs/Text-Generation-GAN/lib/python3.9/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Text-Generation-GAN/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/data.py:263\u001b[0m, in \u001b[0;36mData.get_next_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m offset \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[0;32m--> 263\u001b[0m     src2idx[j], atten2final[j, :, \u001b[38;5;241m1\u001b[39m], sum2final[j, :, \u001b[38;5;241m2\u001b[39m], src_len[j], sum_len[j], oov[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     atten2final[j, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m j\n\u001b[1;32m    265\u001b[0m     sum2final[j, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m j\n",
      "File \u001b[0;32m~/Dropbox/WPI/Senior/Fall/NLP/Text-Generation-GAN/SummaryGeneration/data.py:113\u001b[0m, in \u001b[0;36mData.word2id\u001b[0;34m(self, _context, _summary)\u001b[0m\n\u001b[1;32m    111\u001b[0m         sum2final[i] \u001b[38;5;241m=\u001b[39m oov[summary[i]]\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         \u001b[43msum2final\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[summary[i]]\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src2idx, atten2final, sum2final, src_len, sum_len, json\u001b[38;5;241m.\u001b[39mdumps(oov)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "train_max_epoch = 2\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch(train_data, data.n_train_batch, coverage_on = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc6baa",
   "metadata": {},
   "source": [
    "#### Generate tokens <a class=\"anchor\" id=\"gen-global-1-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.get_next_epoch()\n",
    "test_data = data.get_next_epoch_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, ref, gen, tokens, scores, attens, gt_attens = None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca53b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feed_dict in train_data:\n",
    "    real, fake, real_len, fake_len = model.sess.run([model.real_reward, model.fake_reward, model.sum_len, model.tokens_len], feed_dict = feed_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859697e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.mean(real[1, 0:int(real_len[1])]))\n",
    "print (np.mean(fake[1, 0:int(fake_len[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for feed_dict in test_data:\n",
    "    tokens, scores, attens = model.beam_search(feed_dict)\n",
    "    src, ref, gen = data.id2word(feed_dict, tokens)\n",
    "    gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c023651",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "print (\"\".join(src[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "print (\"\".join(ref[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "print (\"\".join(gen[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "print (scores[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345043fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_k_tokens(top_k, coverage):\n",
    "    test_data = data.get_next_epoch_test()\n",
    "    src = [[] for i in range(top_k)]\n",
    "    ref = [[] for i in range(top_k)]\n",
    "    gen = [[] for i in range(top_k)]\n",
    "    for feed_dict in test_data:\n",
    "        tokens, scores, attens = model.beam_search(feed_dict, coverage_on = coverage, top_k = top_k)\n",
    "        for i in range(top_k):\n",
    "            src[i], ref[i], gen[i] = data.id2word(feed_dict, tokens[i])\n",
    "#         feed_dict['coverage_on:0'] = coverage\n",
    "#         gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "        break\n",
    "    return src, ref, gen, scores\n",
    "\n",
    "def print_generated_tokens(src, ref, gen, scores):\n",
    "    print (\"\".join(src[0][0]).replace(\"(OOV)\", \"\"), end = '\\n\\n')\n",
    "    print (\"\".join(ref[0][0]).replace(\"(OOV)\", \"\"), end = '\\n\\n')\n",
    "    for i in range(len(src)):\n",
    "        print (\"\".join(gen[i][0]).replace(\"(OOV)\", \"\"))\n",
    "        print (scores[i][0], end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6094fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_src, test1_ref, test1_gen, test1_scores = generate_top_k_tokens(10, False)\n",
    "print_generated_tokens(test1_src, test1_ref, test1_gen, test1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270aac8",
   "metadata": {},
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-1-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33171bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "def rouge_evaluation(ref, gen):\n",
    "    # remove empty generations\n",
    "    ref = [ref[i] if not (gen[i] == \"\") for i in range(len(ref))]\n",
    "    gen = [gen[i] if not (gen[i] == \"\") for i in range(len(gen))]\n",
    "    # calculate rouge score\n",
    "    rouge_score = rouge.get_scores(new_gens, new_refs)\n",
    "    r1, r2, rl = 0., 0., 0.\n",
    "    for score in rouge_score:\n",
    "        r1 = r1 + score['rouge-1']['f']\n",
    "        r2 = r2 + score['rouge-2']['f']\n",
    "        rl = rl + score['rouge-l']['f']\n",
    "    r1 /= len(rouge_score)\n",
    "    r2 /= len(rouge_score)\n",
    "    rl /= len(rouge_score)\n",
    "    print (r1, r2, rl)\n",
    "    return r1, r2, rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_r1, test1_r2, test1_rl = rouge_evaluation(test1_ref, test1_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b25bf7",
   "metadata": {},
   "source": [
    "### Train with coverage<a class=\"anchor\" id=\"train-global-1-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bf222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_epoch = 2\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch(train_data, data.n_train_batch, coverage_on = True, model_name = 'with_coverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74923303",
   "metadata": {},
   "source": [
    "#### Generate tokens<a class=\"anchor\" id=\"gen-global-1-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df621e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_src, test2_ref, test2_gen = generate_top_k_tokens(3, False)\n",
    "print_generated_tokens(test2_src, test2_ref, test2_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af5d03",
   "metadata": {},
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-1-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86502080",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_r1, test2_r2, test2_rl = rouge_evaluation(test2_ref, test2_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fe825",
   "metadata": {},
   "source": [
    "## Train GAN<a class=\"anchor\" id=\"train-global-2\"></a>\n",
    "### Pretrain Discriminator<a class=\"anchor\" id=\"train-global-2-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_epoch = 2\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step_2)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch_pre_dis(train_data, data.n_train_batch, coverage_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bafcfa",
   "metadata": {},
   "source": [
    "#### Generate tokens<a class=\"anchor\" id=\"gen-global-2-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b36de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_src, test3_ref, test3_gen = generate_top_k_tokens(3, False)\n",
    "print_generated_tokens(test3_src, test3_ref, test3_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eda911",
   "metadata": {},
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-2-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_r1, test3_r2, test3_rl = rouge_evaluation(test3_ref, test3_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a2b39",
   "metadata": {},
   "source": [
    "### Adversarial Training<a class=\"anchor\" id=\"train-global-2-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_epoch = 12\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step_2)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch_unsup(train_data, data.n_train_batch, coverage_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239b069",
   "metadata": {},
   "source": [
    "#### Generate Tokens<a class=\"anchor\" id=\"gen-global-2-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa71902",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4_src, test4_ref, test4_gen = generate_top_k_tokens(3, False)\n",
    "print_generated_tokens(test4_src, test4_ref, test4_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb0f8c",
   "metadata": {},
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-2-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75692b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4_r1, test4_r2, test4_rl = rouge_evaluation(test4_ref, test4_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4408dae",
   "metadata": {},
   "source": [
    "## Analysis & Conclusion<a class=\"anchor\" id=\"analysis-conclusion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e18d5923",
   "metadata": {},
   "source": [
    "## Limitations & Future Work<a class=\"anchor\" id=\"limit-future\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ccb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
