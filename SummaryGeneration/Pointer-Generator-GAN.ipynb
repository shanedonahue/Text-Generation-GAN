{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768eee96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adversarial Training on Pointer Generator\n",
    "## Introduction\n",
    "    The beginning of the introduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b20d6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Table Of Contents:\n",
    "* [Load Data & Initialize Model](#load-initialize)\n",
    "* [Train Pointer Generator](#train-global-1)\n",
    "    * [Without Coverage](#train-global-1-sub-1)\n",
    "        * [Generate Tokens](#gen-global-1-sub-1)\n",
    "        * [Rouge Evaluation](#rouge-global-1-sub-1)\n",
    "    * [With Coverage](#train-global-1-sub-2)\n",
    "        * [Generate Tokens](#gen-global-1-sub-2)\n",
    "        * [Rouge Evaluation](#rouge-global-1-sub-2)\n",
    "* [Train Generative Adversarial Network](#train-global-2)\n",
    "    * [Pretrain Discriminator](#train-global-2-sub-1)\n",
    "        * [Generate Tokens](#gen-global-2-sub-1)\n",
    "        * [Rouge Evaluation](#rouge-global-2-sub-1)\n",
    "    * [Adversarial Training](#train-global-2-sub-2)\n",
    "        * [Generate Tokens](#gen-global-2-sub-2)\n",
    "        * [Rouge Evaluation](#rouge-global-2-sub-2)\n",
    "* [Analysis & Conclusion](#analysis-conclusion)\n",
    "* [Limitations & Future Work](#limit-future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b433a88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data & Initialize Model <a class=\"anchor\" id=\"load-initialize\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe09c6e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:214: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.enc_fw_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='encoder_forward_cell')\n",
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:215: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.enc_bw_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='encoder_backward_cell')\n",
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:250: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.dec_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, state_is_tuple=False, name='decoder_cell')\n",
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:462: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.dis_enc_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='dis_enc_unit')\n",
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:464: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.dis_dec_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='dis_dec_unit')\n",
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:495: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.bas_enc_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='bas_enc_unit')\n",
      "A:\\SHANE_STUFF\\Text-Generation-GAN\\SummaryGeneration\\model.py:497: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  self.bas_dec_unit = tf.compat.v1.nn.rnn_cell.LSTMCell(self.num_unit, name='bas_dec_unit')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data import Data\n",
    "from model import SummaryModel\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.logging.set_verbosity('ERROR')\n",
    "\n",
    "parser = argparse.ArgumentParser(description = 'Train/Test summarization model', formatter_class = argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# Import Setting\n",
    "parser.add_argument(\"--doc_file\", type = str, default = './data/doc.p', help = 'path to document file')\n",
    "parser.add_argument(\"--vocab_file\", type = str, default = './data/vocab.p', help = 'path to vocabulary file')\n",
    "parser.add_argument(\"--emb_file\", type = str, default = './data/emb.p', help = 'path to embedding file')\n",
    "parser.add_argument(\"--src_time\", type = int, default = 200, help = 'maximal # of time steps in source text')\n",
    "parser.add_argument(\"--sum_time\", type = int, default = 50, help = 'maximal # of time steps in summary')\n",
    "parser.add_argument(\"--max_oov_bucket\", type = int, default = 280, help = 'maximal # of out-of-vocabulary word in one summary')\n",
    "parser.add_argument(\"--train_ratio\", type = float, default = 0.8, help = 'ratio of training data')\n",
    "parser.add_argument(\"--seed\", type = int, default = 888, help = 'seed for spliting data')\n",
    "\n",
    "# Saving Setting\n",
    "parser.add_argument(\"--log\", type = str, default = './log/', help = 'logging directory')\n",
    "parser.add_argument(\"--save\", type = str, default = './model/', help = 'model saving directory')\n",
    "parser.add_argument(\"--checkpoint\", type = str, help = 'path to checkpoint point')\n",
    "parser.add_argument(\"--autosearch\", type = bool, default = False, help = \"[NOT AVAILABLE] Set 'True' if searching for latest checkpoint\")\n",
    "parser.add_argument(\"--save_interval\", type = int, default = 1900, help = \"Save interval for training\")\n",
    "\n",
    "# Hyperparameter Setting\n",
    "parser.add_argument(\"--batch_size\", type = int, default = 16, help = 'number of samples in one batch')\n",
    "parser.add_argument(\"--gen_lr\", type = float, default = 1e-3, help = 'learning rate for generator')\n",
    "parser.add_argument(\"--dis_lr\", type = float, default = 1e-3, help = 'learning rate for discriminator')\n",
    "parser.add_argument(\"--cov_weight\", type = float, default = 1e-3, help = 'learning rate for coverage')\n",
    "\n",
    "params = vars(parser.parse_args([]))\n",
    "\n",
    "# params['load_pretrain'] = True\n",
    "# # untrained model with glove embedding fine tuned on NYT dataset\n",
    "# params['checkpoint'] = './model/model_untrain_glove-0' # Uncomment when requiring reloading model\n",
    "\n",
    "model = SummaryModel(**params)\n",
    "data = Data(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a3b8db2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49259385\n",
      "0.49308753\n",
      "[['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['A', 'f', 't', 'e', 'r', 'i', 'c', 'e', 's', ' (OOV)', 'C', 'e', 'a', 'd', 'e', 'r', ' (OOV)'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['1', '9', '1', '1', ':', ' (OOV)'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['A', 'f', 't', 'e', 'r', 'i', 'c', 'e', 's', ' (OOV)', 'S', 'e', 'a', 't', 'h', 'e', 's', ' (OOV)', 'S', 'e', 'a', 't', 'h', 'e', 'r', 's', ' (OOV)', 'i', 'n', ' (OOV)', 'I', 'a', 'r', 'e', 's', 't', 'a', 'n', 'i', 'a', 'n', ' (OOV)'], ['1', '9', '1', '1', ':', ' (OOV)'], ['1', '9', '1', '1', ':', ' (OOV)'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['1', '9', '1', '6', ':', ' (OOV)'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S', 'e', 'a', 'd', 'e', 'r', 's', ' (OOV)'], ['A', 'f', 't', 'e', 'r', 'i', 'c', 't', 'i', 'o', 'n', ' (OOV)', 'S'], ['A', 'f', 't', 'e', 'r', 'i', 'a', 't', 'i', 'o', 'n', ' (OOV)', 'S', 'e', 's', 't', 'e', 'r', 'e', 's', ' (OOV)', 'A', 't', 't', 'a', 'c', 'k', 's', ' (OOV)', 'i', 'n', ' (OOV)', 'I'], ['1', '9', '1', '1', ':', ' (OOV)']]\n"
     ]
    }
   ],
   "source": [
    "train_data = data.get_next_epoch()\n",
    "test_data = data.get_next_epoch_test()\n",
    "src, ref, gen, tokens, scores, attens, gt_attens = None, None, None, None, None, None, None\n",
    "for feed_dict in train_data:\n",
    "    real, fake, real_len, fake_len = model.sess.run(\n",
    "        [model.real_reward, model.fake_reward, model.sum_len, model.tokens_len], feed_dict=feed_dict)\n",
    "    print(np.mean(real[1, 0:int(real_len[1])]))\n",
    "    print(np.mean(fake[1, 0:int(fake_len[1])]))\n",
    "    break\n",
    "\n",
    "for feed_dict in test_data:\n",
    "    tokens, scores, attens = model.beam_search(feed_dict)\n",
    "    src, ref, gen = data.id2word(feed_dict, tokens)\n",
    "    gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "#     print(src, ref, gen, gt_attens)\n",
    "    print(gen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42c570",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Pointer Generator<a class=\"anchor\" id=\"train-global-1\"></a>\n",
    "### Train without coverage<a class=\"anchor\" id=\"train-global-1-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5727c9ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from step 4\n",
      "Train Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518d50ee7b6d4f3fb11302612dd691d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_max_epoch = 1\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch(train_data, data.n_train_batch, coverage_on = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc6baa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Generate tokens <a class=\"anchor\" id=\"gen-global-1-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afc5ef6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = data.get_next_epoch()\n",
    "test_data = data.get_next_epoch_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecaf15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "src, ref, gen, tokens, scores, attens, gt_attens = None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca53b06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for feed_dict in train_data:\n",
    "    real, fake, real_len, fake_len = model.sess.run([model.real_reward, model.fake_reward, model.sum_len, model.tokens_len], feed_dict = feed_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859697e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print (np.mean(real[1, 0:int(real_len[1])]))\n",
    "print (np.mean(fake[1, 0:int(fake_len[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8ad83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for feed_dict in test_data:\n",
    "    tokens, scores, attens = model.beam_search(feed_dict)\n",
    "    src, ref, gen = data.id2word(feed_dict, tokens)\n",
    "    gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c023651",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "print (\"\".join(src[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "print (\"\".join(ref[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "print (\"\".join(gen[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "print (scores[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = data.get_next_epoch()\n",
    "test_data = data.get_next_epoch_test()\n",
    "src, ref, gen, tokens, scores, attens, gt_attens = None, None, None, None, None, None, None\n",
    "for feed_dict in train_data:\n",
    "    real, fake, real_len, fake_len = model.sess.run(\n",
    "        [model.real_reward, model.fake_reward, model.sum_len, model.tokens_len], feed_dict=feed_dict)\n",
    "    print(np.mean(real[1, 0:int(real_len[1])]))\n",
    "    print(np.mean(fake[1, 0:int(fake_len[1])]))\n",
    "    break\n",
    "\n",
    "for feed_dict in test_data:\n",
    "    tokens, scores, attens = model.beam_search(feed_dict)\n",
    "    src, ref, gen = data.id2word(feed_dict, tokens)\n",
    "    gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "#     print(src, ref, gen, gt_attens)\n",
    "    x = 0\n",
    "    print (\"\".join(src[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "    print (\"\".join(ref[x]).replace(\"(OOV)\",\"\"), end = '\\n\\n')\n",
    "    print (gen)\n",
    "#     for i in range(len(src)):\n",
    "#         print (\"\".join(gen[x][i]))\n",
    "    break\n",
    "\n",
    "def generate_top_k_tokens(top_k, coverage):\n",
    "    test_data = data.get_next_epoch_test()\n",
    "    src = [[] for i in range(top_k)]\n",
    "    ref = [[] for i in range(top_k)]\n",
    "    gen = [[] for i in range(top_k)]\n",
    "    for feed_dict in test_data:\n",
    "        tokens, scores, attens = model.beam_search(feed_dict, coverage_on = coverage, top_k = top_k)\n",
    "        for i in range(top_k):\n",
    "            src[i], ref[i], gen[i] = data.id2word(feed_dict, tokens[i])\n",
    "#         feed_dict['coverage_on:0'] = coverage\n",
    "#         gt_attens = model.sess.run(model.atten_dist, feed_dict = feed_dict)\n",
    "        break\n",
    "    return src, ref, gen, scores\n",
    "\n",
    "def print_generated_tokens(src, ref, gen, scores):\n",
    "    print (\"\".join(src[0][0]).replace(\"(OOV)\", \"\"), end = '\\n\\n')\n",
    "    print (\"\".join(ref[0][0]).replace(\"(OOV)\", \"\"), end = '\\n\\n')\n",
    "    for i in range(len(src)):\n",
    "        print (\"\".join(gen[i][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test1_src, test1_ref, test1_gen, test1_scores = generate_top_k_tokens(10, False)\n",
    "print_generated_tokens(test1_src, test1_ref, test1_gen, test1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-1-sub-1\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "def rouge_evaluation(ref, gen):\n",
    "    # remove empty generations\n",
    "    ref = [ref[i] if not (gen[i] == \"\") else for i in range(len(ref))]\n",
    "    gen = [gen[i] if not (gen[i] == \"\") else for i in range(len(gen))]\n",
    "    # calculate rouge score\n",
    "    rouge_score = rouge.get_scores(new_gens, new_refs)\n",
    "    r1, r2, rl = 0., 0., 0.\n",
    "    for score in rouge_score:\n",
    "        r1 = r1 + score['rouge-1']['f']\n",
    "        r2 = r2 + score['rouge-2']['f']\n",
    "        rl = rl + score['rouge-l']['f']\n",
    "    r1 /= len(rouge_score)\n",
    "    r2 /= len(rouge_score)\n",
    "    rl /= len(rouge_score)\n",
    "    print (r1, r2, rl)\n",
    "    return r1, r2, rl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a6f15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test1_r1, test1_r2, test1_rl = rouge_evaluation(test1_ref, test1_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b25bf7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train with coverage<a class=\"anchor\" id=\"train-global-1-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bf222",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_max_epoch = 2\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch(train_data, data.n_train_batch, coverage_on = True, model_name = 'with_coverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74923303",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Generate tokens<a class=\"anchor\" id=\"gen-global-1-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df621e06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test2_src, test2_ref, test2_gen = generate_top_k_tokens(3, False)\n",
    "print_generated_tokens(test2_src, test2_ref, test2_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af5d03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-1-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86502080",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test2_r1, test2_r2, test2_rl = rouge_evaluation(test2_ref, test2_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fe825",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train GAN<a class=\"anchor\" id=\"train-global-2\"></a>\n",
    "### Pretrain Discriminator<a class=\"anchor\" id=\"train-global-2-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80821d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_max_epoch = 2\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step_2)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch_pre_dis(train_data, data.n_train_batch, coverage_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bafcfa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Generate tokens<a class=\"anchor\" id=\"gen-global-2-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b36de8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test3_src, test3_ref, test3_gen = generate_top_k_tokens(3, False)\n",
    "print_generated_tokens(test3_src, test3_ref, test3_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eda911",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-2-sub-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcbccb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test3_r1, test3_r2, test3_rl = rouge_evaluation(test3_ref, test3_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a2b39",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Adversarial Training<a class=\"anchor\" id=\"train-global-2-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53e6f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_max_epoch = 12\n",
    "print (f'Start from step {model.sess.run(model.gen_global_step_2)}')\n",
    "for i in range(train_max_epoch):\n",
    "    print (f'Train Epoch {i}')\n",
    "    train_data = data.get_next_epoch()\n",
    "    model.train_one_epoch_unsup(train_data, data.n_train_batch, coverage_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239b069",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Generate Tokens<a class=\"anchor\" id=\"gen-global-2-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa71902",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test4_src, test4_ref, test4_gen = generate_top_k_tokens(3, False)\n",
    "print_generated_tokens(test4_src, test4_ref, test4_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb0f8c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rouge Evaluation<a class=\"anchor\" id=\"rouge-global-2-sub-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75692b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test4_r1, test4_r2, test4_rl = rouge_evaluation(test4_ref, test4_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4408dae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis & Conclusion<a class=\"anchor\" id=\"analysis-conclusion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88efb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e18d5923",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Limitations & Future Work<a class=\"anchor\" id=\"limit-future\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ccb98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}